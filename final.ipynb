{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fe30c0a9-0675-4654-8704-a12929450303",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "import logging\n",
    "import os\n",
    "import shutil\n",
    "import sys\n",
    "\n",
    "import geopandas as gpd\n",
    "import numpy\n",
    "import pandas\n",
    "import pygeoprocessing\n",
    "import pygeoprocessing.kernels\n",
    "import scipy\n",
    "import shapely\n",
    "from osgeo import gdal\n",
    "gdal.UseExceptions()\n",
    "\n",
    "logger = logging.getLogger(\"pygeoprocessing\")\n",
    "logger.addHandler(logging.StreamHandler(stream=sys.stdout))\n",
    "logger.setLevel('DEBUG')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78a8bcfd-e414-49cd-bf69-1e839b06ae22",
   "metadata": {},
   "source": [
    "# Preprocessing the Trucost data\n",
    "\n",
    "This notebook just shows what pre-processing was done, but not why. A lot of effort went into figuring out the S&P Trucost dataset since it was poorly formatted and documented. For more details, see:\n",
    "- https://docs.google.com/spreadsheets/d/1x5x7Ovw9tprtGWmcWgSt6bB4h0jY2O-BLFR6Y2DnMjU\n",
    "- https://docs.google.com/document/d/17VCWLeJAqct9yHqKXjLqIS7SU6zd-R1OYuLVqG7yaUc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b22ee6c9-6c35-4616-8c5d-299e923c6d01",
   "metadata": {},
   "source": [
    "## read in data\n",
    "Import dependencies and read in the original CSVs.\n",
    "\n",
    "By default, read_csv converts certain values to numpy.nan including ‘’, ‘NA’, ‘NULL’ and others. I'm adding 'No Data' to that list because I know that it exists in some columns.\n",
    "\n",
    "Using `dtype='string'` preserves the numeric values exactly as they are in the original file. (Instead of parsing them as floats, which can introduce error)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e301c738-e515-49bf-8829-41aa98162da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "\n",
    "gdrive_path = '/Users/emily/Library/CloudStorage/GoogleDrive-esoth@stanford.edu/Shared drives/MS-Planet-NatCap corporate footprinting/'\n",
    "\n",
    "# Paths to input data in google cloud storage\n",
    "asset_csv_path = f'{gdrive_path}/ES_modeling_data/source_data/Stan_Physical_AL_Expanded_LYr_20210528.csv'\n",
    "owner_csv_path = f'{gdrive_path}/ES_modeling_data/source_data/Stan_PhyscialRisk_Owner_MI_LYr_20210528.csv'\n",
    "ultimate_parent_csv_path = f'{gdrive_path}/ES_modeling_data/source_data/Stan_PhysicalRisk_Parent_MI_LYr_20210528.csv'\n",
    "\n",
    "# Relative paths for outputs\n",
    "asset_output_path = 'preprocessed_assets.csv'\n",
    "\n",
    "asset_df = pandas.read_csv(asset_csv_path, dtype='string')\n",
    "owner_df = pandas.read_csv(owner_csv_path, dtype='string')\n",
    "ultimate_parent_df = pandas.read_csv(ultimate_parent_csv_path, dtype='string')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2efce76-6f66-4347-9673-632a830f96a7",
   "metadata": {},
   "source": [
    "## standardize column name capitalization and word separators\n",
    "The column names are inconsistently capitalized and some contain spaces. For consistency, make them all lowercase and replace spaces with underscores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9367157b-fd9d-4cdf-88c4-461d9433559c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in [asset_df, owner_df, ultimate_parent_df]:\n",
    "    # for consistency, convert all column names to lowercase\n",
    "    df.rename(columns=str.lower, inplace=True)\n",
    "    # replace spaces with underscores in all column names\n",
    "    df.rename(columns=lambda x: x.replace(' ', '_'), inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80924e51-c134-4f74-895f-c4feacb5ed3c",
   "metadata": {},
   "source": [
    "## cross-reference the tables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ea4cbb6-a49d-41df-be8b-6b15f60d740d",
   "metadata": {},
   "source": [
    "There are 5 identifiers for owner and parent companies: name, MI key, CIQ ID, TC UID, and ISIN. We don't need all five in the asset table - we just need one to cross-reference with the owner ultimate parent tables, which will store the other four identifiers and info.\n",
    "\n",
    "The MI key is defined for the most companies, so we'll keep that and drop the others. \n",
    "\n",
    "But first, verify that the other IDs match up when we cross-reference by the MI key.\n",
    "\n",
    "Note: I'm not asserting that the `name`s match because I know there are inconsistencies and that's okay. We'll use the name as it appears in the owner or ultimate parent table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f1d54fce-4227-484a-ba44-746d51ed82de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assert that all 4 owner IDs match across the asset and owner tables\n",
    "# The owner ISIN provided is the same as the owner ISIN derived by \n",
    "# cross-referencing with the owner table on the MI key\n",
    "asset_and_owner = pandas.merge(\n",
    "    left=asset_df, right=owner_df[['owner_mi_key', 'ultimate_parent_mi_key']],\n",
    "    left_on='owner_mi_key', right_on='owner_mi_key', \n",
    "    suffixes=('_asset', '_owner'))\n",
    "\n",
    "asset_and_parent = pandas.merge(\n",
    "    left=asset_and_owner, right=ultimate_parent_df[['ultimate_parent_mi_key', 'ultimate_parent_isin', 'sector']],\n",
    "    left_on='ultimate_parent_mi_key_owner', right_on='ultimate_parent_mi_key', \n",
    "    suffixes=('_asset', '_parent'))\n",
    "assert asset_and_parent['ultimate_parent_isin_asset'].equals(asset_and_parent['ultimate_parent_isin_parent'])\n",
    "assert asset_and_parent['sector_asset'].equals(asset_and_parent['sector_parent'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fb31b683-afb4-40ab-b203-7a8743bbb967",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4058 duplicate rows in asset table\n"
     ]
    }
   ],
   "source": [
    "print(sum(asset_df.duplicated()), 'duplicate rows in asset table')\n",
    "asset_df = asset_df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1f0e172-9c77-4342-945b-901732fb108b",
   "metadata": {},
   "source": [
    "## clean up categorical data\n",
    "Clean up a couple of minor issues in categorical data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c279f677-15a9-4f68-837b-4717b935efc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# facility_category: consolidate value spellings\n",
    "asset_df['facility_category'] = asset_df['facility_category'].replace('Data Centre', 'Data Center')\n",
    "asset_df['facility_category'] = asset_df['facility_category'].replace('Power Plants', 'Power Plant')\n",
    "\n",
    "# data_source: fix space character\n",
    "asset_df['data_source'] = asset_df['data_source'].replace(\n",
    "    'European Pollutant Release\\xa0and Transfer Register',\n",
    "    'European Pollutant Release and Transfer Register')\n",
    "\n",
    "# Remove trailing whitespace from activity_description values\n",
    "asset_df['activity_description'] = asset_df['activity_description'].apply(lambda x: x if pandas.isna(x) else x.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1afce46e-6173-4532-b40a-2bfcc1fab575",
   "metadata": {},
   "source": [
    "This wasn't documented, but it seems that the facility category and activity description go together. For most facility categories, the activity description is identical to the facility category. A few categories have their own set of activity descriptions that provide more detail about the asset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f2451e2b-8069-4e32-80d9-b9b13962e1d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "facility_categories = set(asset_df['facility_category'].unique())\n",
    "asset_df['activity_description'] = asset_df['activity_description'].apply(\n",
    "    lambda x: None if x in facility_categories else x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e338658-c1da-4fd3-8b14-275ec365bdb0",
   "metadata": {},
   "source": [
    "## add a unique id\n",
    "The asset table has no unique identifier for each row. Create one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "62d8490f-a9f3-4950-b091-eacefa1214ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "asset_df['id'] = range(0, asset_df.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecc5ba0e-54a8-4393-8a9a-a6643d0ed863",
   "metadata": {},
   "source": [
    "## reorder columns\n",
    "Check that the asset dataframe has all the expected columns, then organize them into an arbitrary order that I like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e8208e79-0c70-4b82-9fe7-2e764d6287c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The 'sector' column actually contains GICS subindustries, not sectors.\n",
    "# Rename it accordingly\n",
    "asset_df = asset_df.rename(columns={'sector': 'gics_subindustry'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3465d851-3b45-417e-b6da-da0054528d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "asset_df = asset_df[[\n",
    "    'id',\n",
    "    'asset_name',\n",
    "    'latitude',\n",
    "    'longitude',\n",
    "    'facility_category',\n",
    "    'activity_description',\n",
    "    'ultimate_parent_isin',\n",
    "    'gics_subindustry']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e361663-0607-47ce-8454-97a4948f3766",
   "metadata": {},
   "source": [
    "## save the preprocessed data to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fbc354bc-b945-41f7-bda7-be5d678ff1dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use empty string to represent null\n",
    "asset_df.to_csv(asset_output_path, na_rep='', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2f7ab6f-86d3-416b-bf2c-18f7bc3e33c7",
   "metadata": {},
   "source": [
    "# Prepare the ecosystem and biodiversity layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1c01f8e9-39f0-4da3-b5c9-28e60afc8b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update this to point to your local Google Drive\n",
    "drive_path = '/Users/emily/Library/CloudStorage/GoogleDrive-esoth@stanford.edu/Shared drives/MS-Planet-NatCap corporate footprinting/'\n",
    "data_dir = drive_path + 'ES_modeling_data/script data/aligned_with_PNV/'\n",
    "\n",
    "base_endemic_biodiversity_path = data_dir + 'biodiversity_endemic_index.tif'\n",
    "base_redlist_species_path = data_dir + 'biodiversity_RedList.tif'\n",
    "base_species_richness_path = data_dir + 'biodiversity_species_richness_index.tif'\n",
    "base_kba_path = data_dir + 'biodiversity_KBAs.tif'\n",
    "base_coastal_risk_reduction_service_path = data_dir + 'coastal_risk_reduction_for_coastal_populations.tif'\n",
    "base_nature_access_path = data_dir + 'nature_access_for_people.tif'\n",
    "base_nitrogen_retention_service_path = data_dir + 'nitrogen_retention_for_downstream_populations.tif'\n",
    "base_sediment_retention_service_path = data_dir + 'sediment_deposition_for_downstream_populations.tif'\n",
    "\n",
    "pnv_path = data_dir + 'PNV_full_on_ESA_md5_24fe98_EckertIV_Q.tif'\n",
    "pnv_nodata = pygeoprocessing.get_raster_info(pnv_path)['nodata'][0]\n",
    "\n",
    "target_layers = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c77249f0-1b08-4a03-921f-a017eaed2152",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Create KBA within 1 kilometer raster\n",
    "The base KBA raster represents the number of KBAs covering a pixel (0, 1, or 2).\n",
    "Create a KBA-within-1km raster, where 1 means there is a KBA within 1km of the pixel, and 0 means there is no KBA within 1km of the pixel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7a31fb4e-c92c-4f81-aaa1-ea6a7785b03d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300.0\n",
      "transforming bounding box from [-16920793.1795, -6951751.3822, 16920706.8205, 8375548.6178] \n",
      "transforming bounding to [-16920793.1795, -6951751.382200001, 16920706.8205, 8375548.6178] \n",
      "Warp 5.0% complete kba_warped.tif\n",
      "Warp 9.0% complete kba_warped.tif\n",
      "Warp 13.0% complete kba_warped.tif\n",
      "Warp 18.0% complete kba_warped.tif\n",
      "Warp 22.0% complete kba_warped.tif\n",
      "Warp 26.0% complete kba_warped.tif\n",
      "Warp 31.0% complete kba_warped.tif\n",
      "Warp 35.0% complete kba_warped.tif\n",
      "Warp 39.0% complete kba_warped.tif\n",
      "Warp 44.0% complete kba_warped.tif\n",
      "Warp 49.0% complete kba_warped.tif\n",
      "Warp 53.0% complete kba_warped.tif\n",
      "Warp 57.0% complete kba_warped.tif\n",
      "Warp 62.0% complete kba_warped.tif\n",
      "Warp 66.0% complete kba_warped.tif\n",
      "Warp 70.0% complete kba_warped.tif\n",
      "Warp 75.0% complete kba_warped.tif\n",
      "Warp 80.0% complete kba_warped.tif\n",
      "Warp 84.0% complete kba_warped.tif\n",
      "Warp 88.0% complete kba_warped.tif\n",
      "Warp 93.0% complete kba_warped.tif\n",
      "Warp 97.0% complete kba_warped.tif\n",
      "Warp 100.0% complete kba_warped.tif\n",
      "starting convolve\n",
      "start fill work queue thread\n",
      "fill work queue\n",
      "start worker thread\n",
      "88200 sent to workers, wait for worker results\n",
      "convolution worker approximately 1.4% complete on kba_convolved.tif\n",
      "convolution worker approximately 3.0% complete on kba_convolved.tif\n",
      "convolution worker approximately 4.8% complete on kba_convolved.tif\n",
      "convolution worker approximately 6.5% complete on kba_convolved.tif\n",
      "convolution worker approximately 8.2% complete on kba_convolved.tif\n",
      "convolution worker approximately 9.8% complete on kba_convolved.tif\n",
      "convolution worker approximately 11.6% complete on kba_convolved.tif\n",
      "convolution worker approximately 13.5% complete on kba_convolved.tif\n",
      "convolution worker approximately 15.3% complete on kba_convolved.tif\n",
      "convolution worker approximately 17.0% complete on kba_convolved.tif\n",
      "convolution worker approximately 18.7% complete on kba_convolved.tif\n",
      "convolution worker approximately 20.5% complete on kba_convolved.tif\n",
      "convolution worker approximately 22.3% complete on kba_convolved.tif\n",
      "convolution worker approximately 24.0% complete on kba_convolved.tif\n",
      "convolution worker approximately 25.7% complete on kba_convolved.tif\n",
      "convolution worker approximately 27.5% complete on kba_convolved.tif\n",
      "convolution worker approximately 29.3% complete on kba_convolved.tif\n",
      "convolution worker approximately 31.0% complete on kba_convolved.tif\n",
      "convolution worker approximately 32.8% complete on kba_convolved.tif\n",
      "convolution worker approximately 34.6% complete on kba_convolved.tif\n",
      "convolution worker approximately 36.3% complete on kba_convolved.tif\n",
      "convolution worker approximately 38.1% complete on kba_convolved.tif\n",
      "convolution worker approximately 39.7% complete on kba_convolved.tif\n",
      "convolution worker approximately 41.5% complete on kba_convolved.tif\n",
      "convolution worker approximately 43.2% complete on kba_convolved.tif\n",
      "convolution worker approximately 44.9% complete on kba_convolved.tif\n",
      "convolution worker approximately 46.6% complete on kba_convolved.tif\n",
      "convolution worker approximately 48.3% complete on kba_convolved.tif\n",
      "convolution worker approximately 50.1% complete on kba_convolved.tif\n",
      "convolution worker approximately 51.8% complete on kba_convolved.tif\n",
      "convolution worker approximately 53.6% complete on kba_convolved.tif\n",
      "convolution worker approximately 55.3% complete on kba_convolved.tif\n",
      "convolution worker approximately 57.0% complete on kba_convolved.tif\n",
      "convolution worker approximately 58.8% complete on kba_convolved.tif\n",
      "convolution worker approximately 60.6% complete on kba_convolved.tif\n",
      "convolution worker approximately 62.3% complete on kba_convolved.tif\n",
      "convolution worker approximately 64.1% complete on kba_convolved.tif\n",
      "convolution worker approximately 65.8% complete on kba_convolved.tif\n",
      "convolution worker approximately 67.5% complete on kba_convolved.tif\n",
      "convolution worker approximately 69.2% complete on kba_convolved.tif\n",
      "convolution worker approximately 71.0% complete on kba_convolved.tif\n",
      "convolution worker approximately 72.7% complete on kba_convolved.tif\n",
      "convolution worker approximately 74.5% complete on kba_convolved.tif\n",
      "convolution worker approximately 76.3% complete on kba_convolved.tif\n",
      "convolution worker approximately 78.1% complete on kba_convolved.tif\n",
      "convolution worker approximately 80.0% complete on kba_convolved.tif\n",
      "convolution worker approximately 81.8% complete on kba_convolved.tif\n",
      "convolution worker approximately 83.4% complete on kba_convolved.tif\n",
      "convolution worker approximately 84.9% complete on kba_convolved.tif\n",
      "convolution worker approximately 86.7% complete on kba_convolved.tif\n",
      "convolution worker approximately 88.5% complete on kba_convolved.tif\n",
      "convolution worker approximately 90.3% complete on kba_convolved.tif\n",
      "convolution worker approximately 92.1% complete on kba_convolved.tif\n",
      "convolution worker approximately 93.9% complete on kba_convolved.tif\n",
      "convolution worker approximately 95.8% complete on kba_convolved.tif\n",
      "convolution worker approximately 97.2% complete on kba_convolved.tif\n",
      "convolution worker approximately 98.2% complete on kba_convolved.tif\n",
      "convolution worker approximately 99.3% complete on kba_convolved.tif\n",
      "work queue full\n",
      "convolution worker 100.0% complete on kba_convolved.tif\n",
      "starting stats_worker\n",
      "stats worker PID: 29224\n",
      "started stats_worker <Thread(Thread-7 (stats_worker), started daemon 123145464807424)>\n",
      "kba_within_1km.tif 4.3% complete\n",
      "kba_within_1km.tif 8.0% complete\n",
      "kba_within_1km.tif 11.8% complete\n",
      "kba_within_1km.tif 15.3% complete\n",
      "kba_within_1km.tif 18.7% complete\n",
      "kba_within_1km.tif 21.7% complete\n",
      "kba_within_1km.tif 25.0% complete\n",
      "kba_within_1km.tif 28.4% complete\n",
      "kba_within_1km.tif 32.0% complete\n",
      "kba_within_1km.tif 35.1% complete\n",
      "kba_within_1km.tif 38.7% complete\n",
      "kba_within_1km.tif 42.2% complete\n",
      "kba_within_1km.tif 45.8% complete\n",
      "kba_within_1km.tif 49.2% complete\n",
      "kba_within_1km.tif 52.6% complete\n",
      "kba_within_1km.tif 55.8% complete\n",
      "kba_within_1km.tif 59.3% complete\n",
      "kba_within_1km.tif 62.8% complete\n",
      "kba_within_1km.tif 66.5% complete\n",
      "kba_within_1km.tif 70.0% complete\n",
      "kba_within_1km.tif 73.3% complete\n",
      "kba_within_1km.tif 76.8% complete\n",
      "kba_within_1km.tif 80.2% complete\n",
      "kba_within_1km.tif 83.8% complete\n",
      "kba_within_1km.tif 87.2% complete\n",
      "kba_within_1km.tif 90.7% complete\n",
      "kba_within_1km.tif 94.4% complete\n",
      "kba_within_1km.tif 98.2% complete\n",
      "100.0% complete\n",
      "Waiting for raster stats worker result.\n"
     ]
    }
   ],
   "source": [
    "warped_raster_path = 'kba_warped.tif'\n",
    "kernel_path = 'kba_kernel.tif'\n",
    "convolution_path = 'kba_convolved.tif'\n",
    "kba_within_1km_path = 'kba_within_1km.tif'\n",
    "\n",
    "raster_info = pygeoprocessing.get_raster_info(base_kba_path)\n",
    "distance_threshold_m = 1000\n",
    "pixel_size_m = abs(raster_info['pixel_size'][0])\n",
    "print(pixel_size_m)\n",
    "\n",
    "pygeoprocessing.kernels.dichotomous_kernel(\n",
    "    target_kernel_path=kernel_path,\n",
    "    max_distance=distance_threshold_m / pixel_size_m,\n",
    "    normalize=False)\n",
    "\n",
    "# warp with no changes, just to make the block size square before convolving\n",
    "pygeoprocessing.warp_raster(\n",
    "    base_raster_path=base_kba_path, \n",
    "    target_pixel_size=raster_info['pixel_size'], \n",
    "    target_raster_path=warped_raster_path,\n",
    "    resample_method='near')\n",
    "\n",
    "pygeoprocessing.convolve_2d(\n",
    "    signal_path_band=(warped_raster_path, 1),\n",
    "    kernel_path_band=(kernel_path, 1),\n",
    "    target_path=convolution_path)\n",
    "\n",
    "def op(block):\n",
    "    result = numpy.full(block.shape, -1)\n",
    "    valid_mask = ~array_equals_nodata(block, raster_info['nodata'][0])\n",
    "    result[valid_mask] = block[valid_mask] > 0\n",
    "    return result\n",
    "\n",
    "pygeoprocessing.raster_calculator(\n",
    "    base_raster_path_band_const_list=[(convolution_path, 1)],\n",
    "    local_op=lambda array: array > 0,\n",
    "    target_raster_path=kba_within_1km_path,\n",
    "    datatype_target=gdal.GDT_Int16,\n",
    "    nodata_target=255)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fa60f03-3198-4d39-bc37-9d42a03e9123",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Set coastal risk reduction service to zero inland\n",
    "The base coastal risk reduction raster has nodata in non-coastal areas. Set inland areas to zero because we know that they provide no coastal risk reduction service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0e578c44-5cd8-412a-af1d-091fe7a50c9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting stats_worker\n",
      "stats worker PID: 29224\n",
      "started stats_worker <Thread(Thread-8 (stats_worker), started daemon 123145464807424)>\n",
      "crr_masked_inland.tif 3.4% complete\n",
      "crr_masked_inland.tif 5.5% complete\n",
      "crr_masked_inland.tif 7.6% complete\n",
      "crr_masked_inland.tif 9.7% complete\n",
      "crr_masked_inland.tif 11.9% complete\n",
      "crr_masked_inland.tif 14.0% complete\n",
      "crr_masked_inland.tif 16.1% complete\n",
      "crr_masked_inland.tif 18.4% complete\n",
      "crr_masked_inland.tif 20.5% complete\n",
      "crr_masked_inland.tif 22.6% complete\n",
      "crr_masked_inland.tif 24.9% complete\n",
      "crr_masked_inland.tif 27.1% complete\n",
      "crr_masked_inland.tif 29.3% complete\n",
      "crr_masked_inland.tif 31.5% complete\n",
      "crr_masked_inland.tif 33.7% complete\n",
      "crr_masked_inland.tif 36.1% complete\n",
      "crr_masked_inland.tif 38.2% complete\n",
      "crr_masked_inland.tif 40.4% complete\n",
      "crr_masked_inland.tif 42.6% complete\n",
      "crr_masked_inland.tif 44.9% complete\n",
      "crr_masked_inland.tif 47.1% complete\n",
      "crr_masked_inland.tif 49.4% complete\n",
      "crr_masked_inland.tif 51.7% complete\n",
      "crr_masked_inland.tif 54.0% complete\n",
      "crr_masked_inland.tif 56.3% complete\n",
      "crr_masked_inland.tif 58.6% complete\n",
      "crr_masked_inland.tif 60.8% complete\n",
      "crr_masked_inland.tif 63.1% complete\n",
      "crr_masked_inland.tif 65.3% complete\n",
      "crr_masked_inland.tif 68.3% complete\n",
      "crr_masked_inland.tif 72.3% complete\n",
      "crr_masked_inland.tif 76.3% complete\n",
      "crr_masked_inland.tif 80.4% complete\n",
      "crr_masked_inland.tif 84.5% complete\n",
      "crr_masked_inland.tif 88.7% complete\n",
      "crr_masked_inland.tif 92.7% complete\n",
      "crr_masked_inland.tif 96.8% complete\n",
      "100.0% complete\n",
      "Waiting for raster stats worker result.\n"
     ]
    }
   ],
   "source": [
    "target_layers['coastal_risk_reduction_service'] = 'crr_masked_inland.tif'\n",
    "crr_nodata = pygeoprocessing.get_raster_info(\n",
    "    base_coastal_risk_reduction_service_path)['nodata'][0]\n",
    "\n",
    "# Set CRR to 0 inland (where crr == nodata and pnv != nodata)\n",
    "def crr_op(crr_array, pnv_array):\n",
    "    crr_is_nodata = pygeoprocessing.array_equals_nodata(crr_array, crr_nodata)\n",
    "    pnv_is_nodata = pygeoprocessing.array_equals_nodata(pnv_array, pnv_nodata)\n",
    "    crr_array[crr_is_nodata & ~pnv_is_nodata] = 0\n",
    "    return crr_array\n",
    "pygeoprocessing.raster_calculator(\n",
    "    base_raster_path_band_const_list=[\n",
    "        (base_coastal_risk_reduction_service_path, 1), \n",
    "        (pnv_path, 1)], \n",
    "    local_op=crr_op, \n",
    "    target_raster_path=target_layers['coastal_risk_reduction_service'],\n",
    "    datatype_target=gdal.GDT_Float32, \n",
    "    nodata_target=crr_nodata)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c700f784-eb6c-41ab-8547-a4290293e2a1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Set biodiversity layers to nodata in the oceans\n",
    "The base biodiversity layers have 0 in the oceans. Change to nodata, because the biodiversity metrics don't apply to oceans, and the large area of 0 would throw off the percentile calculation.\n",
    "\n",
    "The base ecosystem service layers already have nodata in the oceans. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ac778ba5-e556-43d5-bb44-c0d8a26cf854",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting stats_worker\n",
      "stats worker PID: 29224\n",
      "started stats_worker <Thread(Thread-9 (stats_worker), started daemon 123145464807424)>\n",
      "masked_endemic_biodiversity.tif 5.5% complete\n",
      "masked_endemic_biodiversity.tif 8.7% complete\n",
      "masked_endemic_biodiversity.tif 11.6% complete\n",
      "masked_endemic_biodiversity.tif 14.7% complete\n",
      "masked_endemic_biodiversity.tif 17.5% complete\n",
      "masked_endemic_biodiversity.tif 20.4% complete\n",
      "masked_endemic_biodiversity.tif 23.2% complete\n",
      "masked_endemic_biodiversity.tif 26.0% complete\n",
      "masked_endemic_biodiversity.tif 28.9% complete\n",
      "masked_endemic_biodiversity.tif 31.7% complete\n",
      "masked_endemic_biodiversity.tif 34.5% complete\n",
      "masked_endemic_biodiversity.tif 37.4% complete\n",
      "masked_endemic_biodiversity.tif 40.5% complete\n",
      "masked_endemic_biodiversity.tif 43.3% complete\n",
      "masked_endemic_biodiversity.tif 46.0% complete\n",
      "masked_endemic_biodiversity.tif 48.8% complete\n",
      "masked_endemic_biodiversity.tif 51.4% complete\n",
      "masked_endemic_biodiversity.tif 54.1% complete\n",
      "masked_endemic_biodiversity.tif 56.8% complete\n",
      "masked_endemic_biodiversity.tif 59.4% complete\n",
      "masked_endemic_biodiversity.tif 61.9% complete\n",
      "masked_endemic_biodiversity.tif 64.6% complete\n",
      "masked_endemic_biodiversity.tif 67.3% complete\n",
      "masked_endemic_biodiversity.tif 70.0% complete\n",
      "masked_endemic_biodiversity.tif 72.8% complete\n",
      "masked_endemic_biodiversity.tif 75.5% complete\n",
      "masked_endemic_biodiversity.tif 78.1% complete\n",
      "masked_endemic_biodiversity.tif 80.9% complete\n",
      "masked_endemic_biodiversity.tif 83.8% complete\n",
      "masked_endemic_biodiversity.tif 87.0% complete\n",
      "masked_endemic_biodiversity.tif 90.5% complete\n",
      "masked_endemic_biodiversity.tif 94.1% complete\n",
      "masked_endemic_biodiversity.tif 97.8% complete\n",
      "100.0% complete\n",
      "Waiting for raster stats worker result.\n",
      "starting stats_worker\n",
      "stats worker PID: 29224\n",
      "started stats_worker <Thread(Thread-10 (stats_worker), started daemon 123145464807424)>\n",
      "masked_kba_within_1km.tif 8.6% complete\n",
      "masked_kba_within_1km.tif 15.1% complete\n",
      "masked_kba_within_1km.tif 21.3% complete\n",
      "masked_kba_within_1km.tif 27.6% complete\n",
      "masked_kba_within_1km.tif 34.0% complete\n",
      "masked_kba_within_1km.tif 40.7% complete\n",
      "masked_kba_within_1km.tif 47.4% complete\n",
      "masked_kba_within_1km.tif 54.1% complete\n",
      "masked_kba_within_1km.tif 60.8% complete\n",
      "masked_kba_within_1km.tif 67.3% complete\n",
      "masked_kba_within_1km.tif 73.9% complete\n",
      "masked_kba_within_1km.tif 80.4% complete\n",
      "masked_kba_within_1km.tif 87.1% complete\n",
      "masked_kba_within_1km.tif 94.0% complete\n",
      "100.0% complete\n",
      "Waiting for raster stats worker result.\n",
      "starting stats_worker\n",
      "stats worker PID: 29224\n",
      "started stats_worker <Thread(Thread-11 (stats_worker), started daemon 123145464807424)>\n",
      "masked_redlist_species.tif 6.6% complete\n",
      "masked_redlist_species.tif 11.6% complete\n",
      "masked_redlist_species.tif 16.7% complete\n",
      "masked_redlist_species.tif 21.7% complete\n",
      "masked_redlist_species.tif 26.8% complete\n",
      "masked_redlist_species.tif 31.8% complete\n",
      "masked_redlist_species.tif 36.8% complete\n",
      "masked_redlist_species.tif 41.8% complete\n",
      "masked_redlist_species.tif 46.9% complete\n",
      "masked_redlist_species.tif 52.1% complete\n",
      "masked_redlist_species.tif 57.1% complete\n",
      "masked_redlist_species.tif 62.3% complete\n",
      "masked_redlist_species.tif 67.5% complete\n",
      "masked_redlist_species.tif 72.7% complete\n",
      "masked_redlist_species.tif 77.8% complete\n",
      "masked_redlist_species.tif 83.1% complete\n",
      "masked_redlist_species.tif 88.4% complete\n",
      "masked_redlist_species.tif 93.9% complete\n",
      "masked_redlist_species.tif 99.5% complete\n",
      "100.0% complete\n",
      "Waiting for raster stats worker result.\n",
      "starting stats_worker\n",
      "stats worker PID: 29224\n",
      "started stats_worker <Thread(Thread-12 (stats_worker), started daemon 123145464807424)>\n",
      "masked_species_richness.tif 4.9% complete\n",
      "masked_species_richness.tif 7.8% complete\n",
      "masked_species_richness.tif 10.2% complete\n",
      "masked_species_richness.tif 12.8% complete\n",
      "masked_species_richness.tif 15.5% complete\n",
      "masked_species_richness.tif 17.9% complete\n",
      "masked_species_richness.tif 20.4% complete\n",
      "masked_species_richness.tif 22.9% complete\n",
      "masked_species_richness.tif 25.4% complete\n",
      "masked_species_richness.tif 27.9% complete\n",
      "masked_species_richness.tif 30.4% complete\n",
      "masked_species_richness.tif 32.8% complete\n",
      "masked_species_richness.tif 35.4% complete\n",
      "masked_species_richness.tif 38.0% complete\n",
      "masked_species_richness.tif 40.6% complete\n",
      "masked_species_richness.tif 43.4% complete\n",
      "masked_species_richness.tif 46.0% complete\n",
      "masked_species_richness.tif 48.8% complete\n",
      "masked_species_richness.tif 51.5% complete\n",
      "masked_species_richness.tif 54.1% complete\n",
      "masked_species_richness.tif 57.0% complete\n",
      "masked_species_richness.tif 59.6% complete\n",
      "masked_species_richness.tif 62.3% complete\n",
      "masked_species_richness.tif 65.0% complete\n",
      "masked_species_richness.tif 67.7% complete\n",
      "masked_species_richness.tif 70.5% complete\n",
      "masked_species_richness.tif 73.2% complete\n",
      "masked_species_richness.tif 76.0% complete\n",
      "masked_species_richness.tif 78.7% complete\n",
      "masked_species_richness.tif 81.6% complete\n",
      "masked_species_richness.tif 84.5% complete\n",
      "masked_species_richness.tif 87.7% complete\n",
      "masked_species_richness.tif 91.1% complete\n",
      "masked_species_richness.tif 94.6% complete\n",
      "masked_species_richness.tif 98.2% complete\n",
      "100.0% complete\n",
      "Waiting for raster stats worker result.\n"
     ]
    }
   ],
   "source": [
    "# Set biodiversity layers to nodata in the oceans (where biodiversity layer == 0 and pnv == nodata)\n",
    "for key, base_path in [\n",
    "        ('endemic_biodiversity', base_endemic_biodiversity_path),\n",
    "        ('kba_within_1km', kba_within_1km_path),\n",
    "        ('redlist_species',  base_redlist_species_path),\n",
    "        ('species_richness', base_species_richness_path)]:\n",
    "    es_raster_info = pygeoprocessing.get_raster_info(base_path)\n",
    "    es_nodata = es_raster_info['nodata'][0]\n",
    "    es_dtype = es_raster_info['datatype']\n",
    "    target_layers[key] = f'masked_{key}.tif'\n",
    "    \n",
    "    def mask(es_array, pnv_array):\n",
    "        pnv_is_nodata = pygeoprocessing.array_equals_nodata(pnv_array, pnv_nodata)\n",
    "        es_array[(es_array == 0) & pnv_is_nodata] = es_nodata\n",
    "        return es_array\n",
    "        \n",
    "    pygeoprocessing.raster_calculator(\n",
    "        base_raster_path_band_const_list=[(base_path, 1), (pnv_path, 1)],\n",
    "        local_op=mask, \n",
    "        target_raster_path=target_layers[key], \n",
    "        datatype_target=es_dtype, \n",
    "        nodata_target=es_nodata)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "93a67b1c-3922-4afe-a69c-acc0cd64dea0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'coastal_risk_reduction_service': 'crr_masked_inland.tif',\n",
      " 'endemic_biodiversity': 'masked_endemic_biodiversity.tif',\n",
      " 'kba_within_1km': 'masked_kba_within_1km.tif',\n",
      " 'nature_access': '/Users/emily/Library/CloudStorage/GoogleDrive-esoth@stanford.edu/Shared '\n",
      "                  'drives/MS-Planet-NatCap corporate '\n",
      "                  'footprinting/ES_modeling_data/script '\n",
      "                  'data/aligned_with_PNV/nature_access_for_people.tif',\n",
      " 'nitrogen_retention_service': '/Users/emily/Library/CloudStorage/GoogleDrive-esoth@stanford.edu/Shared '\n",
      "                               'drives/MS-Planet-NatCap corporate '\n",
      "                               'footprinting/ES_modeling_data/script '\n",
      "                               'data/aligned_with_PNV/nitrogen_retention_for_downstream_populations.tif',\n",
      " 'redlist_species': 'masked_redlist_species.tif',\n",
      " 'sediment_retention_service': '/Users/emily/Library/CloudStorage/GoogleDrive-esoth@stanford.edu/Shared '\n",
      "                               'drives/MS-Planet-NatCap corporate '\n",
      "                               'footprinting/ES_modeling_data/script '\n",
      "                               'data/aligned_with_PNV/sediment_deposition_for_downstream_populations.tif',\n",
      " 'species_richness': 'masked_species_richness.tif'}\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "pp = pprint.PrettyPrinter()\n",
    "\n",
    "target_layers['sediment_retention_service'] = base_sediment_retention_service_path\n",
    "target_layers['nitrogen_retention_service'] = base_nitrogen_retention_service_path\n",
    "target_layers['nature_access'] = base_nature_access_path\n",
    "pp.pprint(target_layers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee0b2397-0203-483b-b192-aa1af5872ad5",
   "metadata": {},
   "source": [
    "# Prepare the ES layer table for the footprinting tool"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5635bd2-215c-4570-a9ee-c9e662bde0c2",
   "metadata": {},
   "source": [
    "## Calculate the 90th percentile of each layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1789a918-38be-470e-a13c-4158dcec9e25",
   "metadata": {},
   "source": [
    "## Format the table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "96b40812-be5f-42bb-befe-380280ae276b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>es_value_path</th>\n",
       "      <th>flag_threshold</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>es_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>coastal_risk_reduction_service</th>\n",
       "      <td>crr_masked_inland.tif</td>\n",
       "      <td>0.000000000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>endemic_biodiversity</th>\n",
       "      <td>masked_endemic_biodiversity.tif</td>\n",
       "      <td>0.000005344048077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kba_within_1km</th>\n",
       "      <td>masked_kba_within_1km.tif</td>\n",
       "      <td>0.000000000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>redlist_species</th>\n",
       "      <td>masked_redlist_species.tif</td>\n",
       "      <td>19.000000000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>species_richness</th>\n",
       "      <td>masked_species_richness.tif</td>\n",
       "      <td>0.067348398268223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sediment_retention_service</th>\n",
       "      <td>/Users/emily/Library/CloudStorage/GoogleDrive-...</td>\n",
       "      <td>122161.820312500000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nitrogen_retention_service</th>\n",
       "      <td>/Users/emily/Library/CloudStorage/GoogleDrive-...</td>\n",
       "      <td>37028224.000000000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nature_access</th>\n",
       "      <td>/Users/emily/Library/CloudStorage/GoogleDrive-...</td>\n",
       "      <td>70930.000000000000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                    es_value_path  \\\n",
       "es_id                                                                               \n",
       "coastal_risk_reduction_service                              crr_masked_inland.tif   \n",
       "endemic_biodiversity                              masked_endemic_biodiversity.tif   \n",
       "kba_within_1km                                          masked_kba_within_1km.tif   \n",
       "redlist_species                                        masked_redlist_species.tif   \n",
       "species_richness                                      masked_species_richness.tif   \n",
       "sediment_retention_service      /Users/emily/Library/CloudStorage/GoogleDrive-...   \n",
       "nitrogen_retention_service      /Users/emily/Library/CloudStorage/GoogleDrive-...   \n",
       "nature_access                   /Users/emily/Library/CloudStorage/GoogleDrive-...   \n",
       "\n",
       "                                         flag_threshold  \n",
       "es_id                                                    \n",
       "coastal_risk_reduction_service        0.000000000000000  \n",
       "endemic_biodiversity                  0.000005344048077  \n",
       "kba_within_1km                        0.000000000000000  \n",
       "redlist_species                      19.000000000000000  \n",
       "species_richness                      0.067348398268223  \n",
       "sediment_retention_service       122161.820312500000000  \n",
       "nitrogen_retention_service     37028224.000000000000000  \n",
       "nature_access                     70930.000000000000000  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pandas.options.display.float_format = '{:.15f}'.format\n",
    "es_ids = []\n",
    "paths = []\n",
    "thresholds = []\n",
    "for key, path in target_layers.items():\n",
    "    es_ids.append(key)\n",
    "    paths.append(path)\n",
    "    thresholds.append(percentile_df[90][key])\n",
    "df = pandas.DataFrame({\n",
    "    'es_id': es_ids,\n",
    "    'es_value_path': paths,\n",
    "    'flag_threshold': thresholds\n",
    "}).set_index('es_id')\n",
    "df.to_csv('es_layer_table.csv', float_format='{:.15f}')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72923629-ea21-4bc6-86f1-641fa5bd23b7",
   "metadata": {},
   "source": [
    "# Prepare point and linear asset data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12bdcba9-ca18-4b91-bc72-3b4aa882c1d4",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Filter to assets owned by companies in MSCI ACWI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "14c35b56-279c-442a-aaf8-701188bc69e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read\n",
      "apply\n"
     ]
    }
   ],
   "source": [
    "# Companies may have multiple ISIN numbers representing different securities\n",
    "# Filter to just those assets whose 'ultimate_parent_isin' is in the MSCI ACWI table 'ISIN' column\n",
    "msci_acwi_df = pandas.read_csv(f'{gdrive_path}/MSCI/msci_acwi_expanded_20221231.csv')\n",
    "msci_acwi_isins = set(msci_acwi_df['ISIN'].unique())\n",
    "\n",
    "print('read')\n",
    "asset_df = pandas.read_csv('preprocessed_assets.csv')\n",
    "\n",
    "print('apply')\n",
    "asset_df = asset_df[asset_df['ultimate_parent_isin'].apply(lambda isin: isin in msci_acwi_isins)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f783824f-2ae7-4d4b-b0f9-e0b575eaf65e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Separate out linear assets and point assets\n",
    "Natural gas pipelines and transmission lines are represented by multiple asset points, which we need to group together and connect to form multilinestrings.\n",
    "\n",
    "All the other asset types are represented by just one point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5e852add-476f-4e27-a61a-56153e91cdcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_asset_df = asset_df[asset_df['facility_category'].apply(  # filter to linear asset types\n",
    "    lambda val: val in {'Natural Gas Pipeline', 'Transmission Line'})].copy()\n",
    "point_asset_df = asset_df[asset_df['facility_category'].apply(  # filter to non-linear asset types\n",
    "    lambda val: val not in {'Natural Gas Pipeline', 'Transmission Line'})].copy()\n",
    "\n",
    "# write out point assets\n",
    "point_asset_df.to_csv('msci_acwi_point_assets.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bf5e13a-d3b3-449d-8f5e-8437823c92d0",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Group linear asset points together into multilinestrings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "acd4f384-5d22-4d39-9a39-4e934791b172",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:2: SyntaxWarning: invalid escape sequence '\\ '\n",
      "<>:2: SyntaxWarning: invalid escape sequence '\\ '\n",
      "/var/folders/zh/dy02ljyd4mj5_nfm158hwcr00000gn/T/ipykernel_29224/4023453138.py:2: SyntaxWarning: invalid escape sequence '\\ '\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "def multilinestring_traversal(graph):\n",
    "    \"\"\"\n",
    "    Traverse a connected, undirected tree graph to produce a multilinestring representing the tree shape.\n",
    "    \n",
    "    Similar to pre-order depth-first traversal, but revisits branch points.\n",
    "    \n",
    "    Example:\n",
    "    \n",
    "    [[0 1 0 0 0 0 0]              0\n",
    "     [1 0 1 0 1 0 0]              |\n",
    "     [0 1 0 1 0 0 0]              1\n",
    "     [0 0 1 0 0 0 0]     =       / \\      ->  [[0, 1, 2, 3], [1, 4, 5], [4, 6]]\n",
    "     [0 1 0 0 0 1 1]            2   4\n",
    "     [0 0 0 0 1 0 0]           /   / \\\n",
    "     [0 0 0 0 1 0 0]]         3   5   6\n",
    "        \n",
    "\n",
    "    Args:\n",
    "        graph (numpy.array): NxN adjacency matrix representing the graph\n",
    "        \n",
    "    Returns:\n",
    "        list[list[int]]. List (representing a multilinestring) of lists (representing linestrings) of \n",
    "        integer indices (0..(N-1))\n",
    "    \"\"\"\n",
    "    # make a copy because we'll modify it\n",
    "    graph = numpy.copy(graph)\n",
    "    \n",
    "    # start on an arbitrary leaf node        \n",
    "    for i, row in enumerate(graph):\n",
    "        if row.sum() == 1:\n",
    "            current_node = i\n",
    "            break\n",
    "    \n",
    "    branch_points = deque([current_node])\n",
    "    linestrings = []\n",
    "\n",
    "    # while there are branches we haven't traversed yet\n",
    "    while branch_points:\n",
    "         \n",
    "        linestring = []  # start a new linestring representing this branch\n",
    "        current_node = branch_points.pop()\n",
    "        next_available_nodes = set([current_node])\n",
    "        \n",
    "        # if at least one neighbor is available, continue along this branch\n",
    "        while next_available_nodes:\n",
    "\n",
    "            # if more than one neighbor is available, store this node to revisit later\n",
    "            if len(next_available_nodes) > 1:\n",
    "                branch_points.append(current_node)\n",
    "                \n",
    "            current_node = next_available_nodes.pop()\n",
    "            \n",
    "            linestring.append(current_node)\n",
    "            \n",
    "            # mark this node as visited\n",
    "            # after this, it won't be available as a neighbor of any other node\n",
    "            graph[:, current_node] = False\n",
    "            \n",
    "            # get the set of nodes that are adjacent to current_node and not yet visited\n",
    "            next_available_nodes = set(list(numpy.argwhere(graph[current_node]).flatten()))\n",
    "        \n",
    "        linestrings.append(linestring)\n",
    "\n",
    "    return linestrings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "450197a1-b5dd-4757-8a51-8370f137754b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Natural Gas Pipeline\n",
      "300 Line Expansion 321\n",
      "85 North Expansion 57\n",
      "ANR Pipeline 15890\n",
      "ANR Storage Company 45\n",
      "Access South 25\n",
      "Adair Southwest 13\n",
      "Agua Blanca Pipeline 963\n",
      "Aitken Creek Looping 23\n",
      "Algonquin Gas Transmission 2853\n",
      "Algonquin Incremental Market (AIM) 97\n",
      "Anchor Point Pipeline 57\n",
      "Apex Expansion 72\n",
      "Appalachian Gateway 275\n",
      "Arkoma Connector Pipeline 138\n",
      "Ashland Pipeline 30\n",
      "Atlantic Bridge 36\n",
      "Atlantic Sunrise Expansion/Central Penn North 148\n",
      "Atlantic Sunrise Expansion/Central Penn South 329\n",
      "Atmos Pipeline-Texas 19607\n",
      "Auburn Gathering System Phase 1 26\n",
      "Auburn Gathering System Phase 2 72\n",
      "Auburn Pipeline Extension 26\n",
      "BC Pipeline 4576\n",
      "Big Pine Expansion 24\n",
      "Big Pine Gathering System 144\n",
      "Big Sandy Pipeline 174\n",
      "Birdsboro Pipeline 36\n",
      "Bison Pipeline 771\n",
      "Bissette Pipeline 45\n",
      "Black Marlin Pipeline 226\n",
      "Blanco-Meeker Expansion 786\n",
      "Blue Union Gathering System 688\n",
      "Bluebonnet Market Express Pipeline 1184\n",
      "Bluestone Gathering Pipeline 119\n",
      "Bluewater Gas Storage Pipeline 102\n",
      "Bobcat Storage 47\n",
      "Brazoria Interconnector Gas Pipeline (BIG) 81\n",
      "Brunswick Pipeline 416\n",
      "CIG High Plains Kiowa Lateral Expansion 24\n",
      "Cameron Access 92\n",
      "Cameron Interstate Pipeline 96\n",
      "Cameron Pipeline Expansion 11\n",
      "Canadian Mainline 7262\n",
      "Carolina Gas Transmission Pipeline 3955\n",
      "Carty Lateral 40\n",
      "Cedar Bayou Lateral 12\n",
      "Central Arkansas Pipeline Expansion (Line BT-39) 74\n",
      "Cheniere Corpus Christi Pipeline 61\n",
      "Cherokee Natural Gas Pipeline 88\n",
      "Cheyenne Plains Gas Pipeline 1042\n",
      "Coastal GasLink Pipeline 1074\n",
      "Colorado Hub Connection 67\n",
      "Colorado Interstate Gas 7372\n",
      "Columbia Gas Pipeline 23594\n",
      "Columbia Gulf Transmission 3796\n",
      "Columbia to Eastover 72\n",
      "Connecticut Expansion 37\n",
      "Cove Point Expansion 327\n",
      "Creole Trail Pipeline Expansion (Zone 1) 100\n",
      "Creole Trail Pipeline Expansion (Zone 2) 125\n",
      "Creole Trail Pipeline Phase I 247\n",
      "Crossroads Pipeline 504\n",
      "DK Pipeline Extension 265\n",
      "Dalton Expansion 588\n",
      "Delta Lateral 94\n",
      "Discovery Gas Transmission Pipeline 662\n",
      "Dominion Cove Point Pipeline 292\n",
      "Dominion Hub III 25\n",
      "Dominion Supply Header 98\n",
      "Dominion Transmission 8410\n",
      "Donlin Gold Mine Pipeline 851\n",
      "Driver Residue Pipeline 58\n",
      "Eagle Ford Shale Pipeline 602\n",
      "Eagle Mountain-Woodfibre Gas Pipeline 76\n",
      "East Pipeline 94\n",
      "East Tennessee Natural Gas Pipeline 3031\n",
      "East Washington Gathering System 53\n",
      "Eastern Extension 82\n",
      "Eastern Panhandle Expansion 10\n",
      "Eastern Panhandle Expansion Segment 1 (Mountaineer Gas) 55\n",
      "Eastern Panhandle Expansion Segment 2 (Mountaineer Gas) 62\n",
      "Eastern Panhandle Expansion Segment 3 (Mountaineer Gas) 16\n",
      "Eastern System Upgrade 20\n",
      "Effort Loop (Leidy D) 37\n",
      "Egan Storage Lateral Loop 26\n",
      "Elba Express Pipeline Phase I (Southern Segment) 305\n",
      "Elba Express Pipeline Phase II(Northern Segment) 226\n",
      "Enable Gas Transmission 14011\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 20\u001b[0m\n\u001b[1;32m     15\u001b[0m gs \u001b[38;5;241m=\u001b[39m gpd\u001b[38;5;241m.\u001b[39mGeoSeries(\n\u001b[1;32m     16\u001b[0m     gpd\u001b[38;5;241m.\u001b[39mpoints_from_xy(group\u001b[38;5;241m.\u001b[39mlongitude, group\u001b[38;5;241m.\u001b[39mlatitude, crs\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEPSG:4326\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     17\u001b[0m )\u001b[38;5;241m.\u001b[39mto_crs(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mESRI:54012\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# calculate distance matrix: distance from each point to each other point\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m distance_matrix \u001b[38;5;241m=\u001b[39m \u001b[43mgs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpoint\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mgs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdistance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpoint\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# calculate minimum spanning tree\u001b[39;00m\n\u001b[1;32m     23\u001b[0m mst \u001b[38;5;241m=\u001b[39m scipy\u001b[38;5;241m.\u001b[39msparse\u001b[38;5;241m.\u001b[39mcsgraph\u001b[38;5;241m.\u001b[39mminimum_spanning_tree(distance_matrix)\u001b[38;5;241m.\u001b[39mtoarray()\n",
      "File \u001b[0;32m~/mambaforge/envs/plugin/envs/morgan-stanley/lib/python3.12/site-packages/geopandas/geoseries.py:660\u001b[0m, in \u001b[0;36mGeoSeries.apply\u001b[0;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[1;32m    657\u001b[0m         kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconvert_dtype\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    659\u001b[0m \u001b[38;5;66;03m# to avoid warning\u001b[39;00m\n\u001b[0;32m--> 660\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    661\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, GeoSeries):\n\u001b[1;32m    662\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcrs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/mambaforge/envs/plugin/envs/morgan-stanley/lib/python3.12/site-packages/pandas/core/series.py:4904\u001b[0m, in \u001b[0;36mSeries.apply\u001b[0;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[0m\n\u001b[1;32m   4769\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[1;32m   4770\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   4771\u001b[0m     func: AggFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4776\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   4777\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[1;32m   4778\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4779\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[1;32m   4780\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4895\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[1;32m   4896\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m   4897\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4898\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4899\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4900\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4901\u001b[0m \u001b[43m        \u001b[49m\u001b[43mby_row\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mby_row\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4902\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4903\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m-> 4904\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mambaforge/envs/plugin/envs/morgan-stanley/lib/python3.12/site-packages/pandas/core/apply.py:1427\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1424\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_compat()\n\u001b[1;32m   1426\u001b[0m \u001b[38;5;66;03m# self.func is Callable\u001b[39;00m\n\u001b[0;32m-> 1427\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mambaforge/envs/plugin/envs/morgan-stanley/lib/python3.12/site-packages/pandas/core/apply.py:1507\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1501\u001b[0m \u001b[38;5;66;03m# row-wise access\u001b[39;00m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m \u001b[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[1;32m   1504\u001b[0m \u001b[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[1;32m   1505\u001b[0m \u001b[38;5;66;03m#  Categorical (GH51645).\u001b[39;00m\n\u001b[1;32m   1506\u001b[0m action \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj\u001b[38;5;241m.\u001b[39mdtype, CategoricalDtype) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1507\u001b[0m mapped \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_values\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1508\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmapper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurried\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\n\u001b[1;32m   1509\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[1;32m   1512\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[1;32m   1513\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[1;32m   1514\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[0;32m~/mambaforge/envs/plugin/envs/morgan-stanley/lib/python3.12/site-packages/pandas/core/base.py:919\u001b[0m, in \u001b[0;36mIndexOpsMixin._map_values\u001b[0;34m(self, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m    916\u001b[0m arr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values\n\u001b[1;32m    918\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[0;32m--> 919\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_action\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    921\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m algorithms\u001b[38;5;241m.\u001b[39mmap_array(arr, mapper, na_action\u001b[38;5;241m=\u001b[39mna_action, convert\u001b[38;5;241m=\u001b[39mconvert)\n",
      "File \u001b[0;32m~/mambaforge/envs/plugin/envs/morgan-stanley/lib/python3.12/site-packages/pandas/core/arrays/base.py:2319\u001b[0m, in \u001b[0;36mExtensionArray.map\u001b[0;34m(self, mapper, na_action)\u001b[0m\n\u001b[1;32m   2299\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmap\u001b[39m(\u001b[38;5;28mself\u001b[39m, mapper, na_action\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   2300\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2301\u001b[0m \u001b[38;5;124;03m    Map values using an input mapping or function.\u001b[39;00m\n\u001b[1;32m   2302\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2317\u001b[0m \u001b[38;5;124;03m        a MultiIndex will be returned.\u001b[39;00m\n\u001b[1;32m   2318\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2319\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmap_array\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_action\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mambaforge/envs/plugin/envs/morgan-stanley/lib/python3.12/site-packages/pandas/core/algorithms.py:1743\u001b[0m, in \u001b[0;36mmap_array\u001b[0;34m(arr, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m   1741\u001b[0m values \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1743\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1745\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer_mask(\n\u001b[1;32m   1746\u001b[0m         values, mapper, mask\u001b[38;5;241m=\u001b[39misna(values)\u001b[38;5;241m.\u001b[39mview(np\u001b[38;5;241m.\u001b[39muint8), convert\u001b[38;5;241m=\u001b[39mconvert\n\u001b[1;32m   1747\u001b[0m     )\n",
      "File \u001b[0;32mlib.pyx:2972\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "Cell \u001b[0;32mIn[34], line 20\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(point)\u001b[0m\n\u001b[1;32m     15\u001b[0m gs \u001b[38;5;241m=\u001b[39m gpd\u001b[38;5;241m.\u001b[39mGeoSeries(\n\u001b[1;32m     16\u001b[0m     gpd\u001b[38;5;241m.\u001b[39mpoints_from_xy(group\u001b[38;5;241m.\u001b[39mlongitude, group\u001b[38;5;241m.\u001b[39mlatitude, crs\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEPSG:4326\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     17\u001b[0m )\u001b[38;5;241m.\u001b[39mto_crs(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mESRI:54012\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# calculate distance matrix: distance from each point to each other point\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m distance_matrix \u001b[38;5;241m=\u001b[39m gs\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m point: \u001b[43mgs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdistance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpoint\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# calculate minimum spanning tree\u001b[39;00m\n\u001b[1;32m     23\u001b[0m mst \u001b[38;5;241m=\u001b[39m scipy\u001b[38;5;241m.\u001b[39msparse\u001b[38;5;241m.\u001b[39mcsgraph\u001b[38;5;241m.\u001b[39mminimum_spanning_tree(distance_matrix)\u001b[38;5;241m.\u001b[39mtoarray()\n",
      "File \u001b[0;32m~/mambaforge/envs/plugin/envs/morgan-stanley/lib/python3.12/site-packages/geopandas/base.py:2577\u001b[0m, in \u001b[0;36mGeoPandasBase.distance\u001b[0;34m(self, other, align)\u001b[0m\n\u001b[1;32m   2483\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdistance\u001b[39m(\u001b[38;5;28mself\u001b[39m, other, align\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m   2484\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Returns a ``Series`` containing the distance to aligned `other`.\u001b[39;00m\n\u001b[1;32m   2485\u001b[0m \n\u001b[1;32m   2486\u001b[0m \u001b[38;5;124;03m    The operation works on a 1-to-1 row-wise manner:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2575\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[1;32m   2576\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2577\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_binary_op\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdistance\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malign\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mambaforge/envs/plugin/envs/morgan-stanley/lib/python3.12/site-packages/geopandas/base.py:63\u001b[0m, in \u001b[0;36m_binary_op\u001b[0;34m(op, this, other, align, *args, **kwargs)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_binary_op\u001b[39m(op, this, other, align, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;66;03m# type: (str, GeoSeries, GeoSeries, args/kwargs) -> Series[bool/float]\u001b[39;00m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Binary operation on GeoSeries objects that returns a Series\"\"\"\u001b[39;00m\n\u001b[0;32m---> 63\u001b[0m     data, index \u001b[38;5;241m=\u001b[39m \u001b[43m_delegate_binary_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malign\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     64\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Series(data, index\u001b[38;5;241m=\u001b[39mindex)\n",
      "File \u001b[0;32m~/mambaforge/envs/plugin/envs/morgan-stanley/lib/python3.12/site-packages/geopandas/base.py:47\u001b[0m, in \u001b[0;36m_delegate_binary_method\u001b[0;34m(op, this, other, align, *args, **kwargs)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;28mtype\u001b[39m(this), \u001b[38;5;28mtype\u001b[39m(other))\n\u001b[0;32m---> 47\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43ma_this\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data, this\u001b[38;5;241m.\u001b[39mindex\n",
      "File \u001b[0;32m~/mambaforge/envs/plugin/envs/morgan-stanley/lib/python3.12/site-packages/geopandas/array.py:693\u001b[0m, in \u001b[0;36mGeometryArray.distance\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    691\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdistance\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n\u001b[1;32m    692\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_geographic_crs(stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m6\u001b[39m)\n\u001b[0;32m--> 693\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_binary_method\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdistance\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mambaforge/envs/plugin/envs/morgan-stanley/lib/python3.12/site-packages/geopandas/array.py:611\u001b[0m, in \u001b[0;36mGeometryArray._binary_method\u001b[0;34m(op, left, right, **kwargs)\u001b[0m\n\u001b[1;32m    608\u001b[0m         _crs_mismatch_warn(left, right, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m7\u001b[39m)\n\u001b[1;32m    609\u001b[0m     right \u001b[38;5;241m=\u001b[39m right\u001b[38;5;241m.\u001b[39m_data\n\u001b[0;32m--> 611\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mvectorized\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mleft\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mright\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mambaforge/envs/plugin/envs/morgan-stanley/lib/python3.12/site-packages/geopandas/_vectorized.py:982\u001b[0m, in \u001b[0;36mdistance\u001b[0;34m(data, other)\u001b[0m\n\u001b[1;32m    980\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdistance\u001b[39m(data, other):\n\u001b[1;32m    981\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m compat\u001b[38;5;241m.\u001b[39mUSE_SHAPELY_20:\n\u001b[0;32m--> 982\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mshapely\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdistance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    983\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m compat\u001b[38;5;241m.\u001b[39mUSE_PYGEOS:\n\u001b[1;32m    984\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m _binary_method(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdistance\u001b[39m\u001b[38;5;124m\"\u001b[39m, data, other)\n",
      "File \u001b[0;32m~/mambaforge/envs/plugin/envs/morgan-stanley/lib/python3.12/site-packages/shapely/decorators.py:77\u001b[0m, in \u001b[0;36mmultithreading_enabled.<locals>.wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m arr \u001b[38;5;129;01min\u001b[39;00m array_args:\n\u001b[1;32m     76\u001b[0m         arr\u001b[38;5;241m.\u001b[39mflags\u001b[38;5;241m.\u001b[39mwriteable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m---> 77\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     79\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m arr, old_flag \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(array_args, old_flags):\n",
      "File \u001b[0;32m~/mambaforge/envs/plugin/envs/morgan-stanley/lib/python3.12/site-packages/shapely/measurement.py:74\u001b[0m, in \u001b[0;36mdistance\u001b[0;34m(a, b, **kwargs)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;129m@multithreading_enabled\u001b[39m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdistance\u001b[39m(a, b, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     50\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Computes the Cartesian distance between two geometries.\u001b[39;00m\n\u001b[1;32m     51\u001b[0m \n\u001b[1;32m     52\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;124;03m    nan\u001b[39;00m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 74\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdistance\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Group points together by facility category\n",
    "for category, category_group in linear_asset_df.groupby('facility_category'):\n",
    "    print(category)\n",
    "\n",
    "    names, geoms = [], []\n",
    "\n",
    "    # Group points together by their asset_name attribute\n",
    "    for name, group in category_group.groupby('asset_name'):\n",
    "        print(name, group.shape[0])\n",
    "        if group.shape[0] == 1:\n",
    "            print(f'Warning: group {name} has only one point, skipping')\n",
    "            continue\n",
    "\n",
    "        # convert to a projected coordinate system for accurate distance calculations\n",
    "        gs = gpd.GeoSeries(\n",
    "            gpd.points_from_xy(group.longitude, group.latitude, crs='EPSG:4326')\n",
    "        ).to_crs('ESRI:54012')\n",
    "\n",
    "        # calculate distance matrix: distance from each point to each other point\n",
    "        distance_matrix = gs.apply(lambda point: gs.distance(point))\n",
    "\n",
    "        # calculate minimum spanning tree\n",
    "        mst = scipy.sparse.csgraph.minimum_spanning_tree(distance_matrix).toarray()\n",
    "\n",
    "        # convert to an undirected, binary adjacency matrix\n",
    "        mst = (mst + mst.T).astype(bool)\n",
    "\n",
    "        multilinestring = multilinestring_traversal(mst)\n",
    "\n",
    "        # convert point indices to point coordinates\n",
    "        multilinestring = shapely.MultiLineString([\n",
    "            shapely.LineString([\n",
    "                shapely.Point(gs[idx].x, gs[idx].y) for idx in linestring\n",
    "            ]) for linestring in multilinestring])\n",
    "\n",
    "        names.append(name)\n",
    "        geoms.append(multilinestring)\n",
    "\n",
    "    new_gdf = gpd.GeoDataFrame(\n",
    "        pd.DataFrame({'name': names}), \n",
    "        geometry=gpd.GeoSeries(geoms), \n",
    "        crs='ESRI:54012')\n",
    "    new_gdf.to_file('msci_acwi_linear_asset_multilinestrings.gpkg', layer=category)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd5bf237-0196-4df0-85fb-e37e7bdffa69",
   "metadata": {},
   "source": [
    "## Manually clean up the linear assets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be453abd-a67d-4900-af2f-228a321a7e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jesse cleaned up the linear assets generated in the previous step\n",
    "cleaned_linear_assets_path = f'{gdrive_path}/ES_modeling_data/asset_footprints/linear_assets_cleaned.gpkg'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4f9747d-b1c6-41f2-b308-a22981360f22",
   "metadata": {},
   "source": [
    "## Buffer linear assets to create polygons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a431206c-0dd0-4d2d-8c06-515750330125",
   "metadata": {},
   "outputs": [],
   "source": [
    "transmission_line_gdf = gpd.read_file(\n",
    "    cleaned_linear_assets_path, \n",
    "    layer='transmission_lines_clean')\n",
    "print(transmission_line_gdf)\n",
    "# cap_style=2: flat end caps (buffer does not extend past the end of each line)\n",
    "transmission_line_gdf.geometry = transmission_line_gdf.geometry.buffer(42.860707, cap_style=2)\n",
    "transmission_line_gdf['facility_category'] = 'Transmission Line'\n",
    "\n",
    "print(transmission_line_gdf)\n",
    "\n",
    "pipeline_gdf = gpd.read_file(\n",
    "    cleaned_linear_assets_path, \n",
    "    layer='pipelines_clean')\n",
    "print(pipeline_gdf)\n",
    "pipeline_gdf.geometry = pipeline_gdf.geometry.buffer(23.9395345, cap_style=2)\n",
    "pipeline_gdf['facility_category'] = 'Natural Gas Pipeline'\n",
    "print(pipeline_gdf)\n",
    "gdf = pd.concat([pipeline_gdf, transmission_line_gdf]) \n",
    "gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4a5051bf-061c-44e7-985e-8a85b7e4f601",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf.to_file('linear_assets_buffered.gpkg', layer='assets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "596484bb-8de0-49b5-994b-a9068cb2285c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6af24d60-9d53-4041-8d60-429d566cd54f",
   "metadata": {},
   "source": [
    "# Run the footprinting tool"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8ed6726-590b-4054-b4c2-852a4948b71a",
   "metadata": {},
   "source": [
    "## Merge ultimate parent data back into linear assets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fdc4ace-1567-42c2-8354-e7cb76360b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_asset_stats_df = pd.read_csv('/Users/emily/natural-capital-footprint-impact/out_linear_assets.csv')\n",
    "asset_name_isins = linear_asset_df.groupby(['asset_name', 'ultimate_parent_isin']).count().reset_index()[['asset_name', 'ultimate_parent_isin']]\n",
    "linear_asset_stats_df = pd.merge(\n",
    "    left=linear_asset_stats_df,\n",
    "    right=asset_name_isins,\n",
    "    left_on='name',\n",
    "    right_on='asset_name',\n",
    "    how='inner').drop('name', axis='columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ff47d14-7334-460c-9813-4ba0fbfdd143",
   "metadata": {},
   "source": [
    "## Consolidate ISINs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f98698aa-371a-4388-91a1-0b421ebd62d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a mapping of expanded to original ISINs,\n",
    "# excluding those without a clear mapping\n",
    "expanded_acwi_df = pd.read_csv('msci_acwi_expanded_20221231.csv')\n",
    "print(len(expanded_acwi_df['ISIN_original'].unique()))\n",
    "counts = expanded_acwi_df['ISIN'].value_counts()\n",
    "duplicated_isins = set(counts[counts > 1].index)\n",
    "\n",
    "isin_is_duplicated = expanded_acwi_df[expanded_acwi_df['ISIN'].apply(\n",
    "    lambda isin: isin in duplicated_isins)]\n",
    "\n",
    "expanded_acwi_df = expanded_acwi_df.drop(isin_is_duplicated.index)\n",
    "print(len(expanded_acwi_df['ISIN_original'].unique()))\n",
    "\n",
    "expanded_to_original_isin = {}\n",
    "for _, row in expanded_acwi_df.iterrows():\n",
    "    expanded_to_original_isin[row['ISIN']] = row['ISIN_original']\n",
    "    \n",
    "original_acwi_df = pd.read_csv('/Users/emily/Downloads/msci_acwi_20221231.csv')\n",
    "all(original_acwi_df['ISIN'] == original_acwi_df['ISIN_original'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a9fb92a-ca35-43ee-b770-7aee382fa53e",
   "metadata": {},
   "outputs": [],
   "source": [
    "asset_df['ultimate_parent_isin'] = asset_df['ultimate_parent_isin'].apply(\n",
    "    lambda isin: expanded_to_original_isin[isin])\n",
    "len(asset_df['ultimate_parent_isin'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be0fa2c-fb29-459d-9083-36b3e8b4b3cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_asset_stats_df['ultimate_parent_isin'] = linear_asset_stats_df['ultimate_parent_isin'].apply(\n",
    "    lambda isin: expanded_to_original_isin[isin])\n",
    "point_asset_stats_df = pd.read_csv('/Users/emily/natural-capital-footprint-impact/out.csv', low_memory=False)\n",
    "point_asset_stats_df['ultimate_parent_isin'] = point_asset_stats_df['ultimate_parent_isin'].apply(\n",
    "    lambda isin: expanded_to_original_isin[isin])\n",
    "asset_stats_df = pd.concat([point_asset_stats_df, linear_asset_stats_df], ignore_index=True)\n",
    "original_isins = set(expanded_acwi_df['ISIN_original'].unique())\n",
    "asset_stats_df['ultimate_parent_isin'].apply(lambda isin: isin not in original_isins).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cbc72c5-2967-4f50-817e-cfae830895cf",
   "metadata": {},
   "source": [
    "## Calculate adjusted sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbffefde-8580-4a1b-a6e0-690937fd2ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "es_ids = [\n",
    "    'coastal_risk_reduction_service',\n",
    "    'nitrogen_retention_service',\n",
    "    'sediment_retention_service',\n",
    "    'nature_access',\n",
    "    'endemic_biodiversity',\n",
    "    'redlist_species',\n",
    "    'species_richness',\n",
    "    'kba_within_1km']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e62189a3-5244-47c5-846e-9c9d1e5300cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "asset_stats_df['footprint_area'] = gpd.GeoSeries.from_wkt(\n",
    "    asset_stats_df['WKT'], crs='ESRI:54012').area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af05523d-3741-4386-83cc-df4bcc0802a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for es_id in es_ids:\n",
    "    asset_stats_df = asset_stats_df.drop(f'{es_id}_sum', axis=1)\n",
    "    if es_id == 'nature_access':\n",
    "        pixel_area = 2000**2\n",
    "    else:\n",
    "        pixel_area = 300**2\n",
    "    asset_stats_df[f'{es_id}_adj_sum'] = (\n",
    "        asset_stats_df[f'{es_id}_mean'] * asset_stats_df['footprint_area'] / pixel_area)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57db876d-ff8e-497e-96bf-cdad4a778044",
   "metadata": {},
   "outputs": [],
   "source": [
    "asset_stats_df.to_csv('msci_acwi_asset_stats.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd06bd16-6a4d-4e33-aff2-ddd4a3987c74",
   "metadata": {},
   "source": [
    "## Create company results table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcce9711-9276-46dc-be68-d9d06a60b1c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from impact.src import aggregate_footprints\n",
    "\n",
    "gs = gpd.GeoSeries.from_wkt(asset_stats_df['WKT'])\n",
    "asset_stats_gdf = gpd.GeoDataFrame(asset_stats_df, geometry=gs, crs=\"ESRI:54012\")\n",
    "\n",
    "aggregate_footprints(\n",
    "    asset_stats_gdf, \n",
    "    'msci_acwi_company_results.csv',\n",
    "    'ultimate_parent_isin',\n",
    "    'polygons')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c2e8f55-7915-485c-8802-42b9715b3aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "company_stats_df = pd.read_csv('msci_acwi_company_results.csv')\n",
    "company_stats_df = company_stats_df.rename(\n",
    "    columns={'ultimate_parent_isin': 'ISIN'}\n",
    ").set_index('ISIN')\n",
    "company_stats_df['total_flagged_no_nature_access'] = None\n",
    "\n",
    "for isin, row in company_stats_df.iterrows():\n",
    "    \n",
    "    company_rows = asset_stats_gdf[\n",
    "        asset_stats_gdf['ultimate_parent_isin'] == isin].copy()\n",
    "    company_rows['any_flag_no_nature_access'] = [False for _ in range(company_rows.shape[0])]\n",
    "\n",
    "    for es_id in es_ids:\n",
    "        if es_id != 'nature_access':\n",
    "            company_rows['any_flag_no_nature_access'] = (\n",
    "                company_rows['any_flag_no_nature_access'] | company_rows[f'{es_id}_flag'])\n",
    "\n",
    "    company_stats_df.loc[isin, 'total_flagged_no_nature_access'] = (\n",
    "        company_rows['any_flag_no_nature_access'].sum())\n",
    "\n",
    "company_stats_df['total_flagged_no_nature_access'] = (\n",
    "    company_stats_df['total_flagged_no_nature_access'].astype(int))\n",
    "company_stats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c3b1101-1893-4234-97e5-f5c9e40f271b",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_acwi_df = pd.read_csv(\n",
    "    '/Users/emily/Downloads/msci_acwi_20221231.csv',\n",
    "    index_col='ISIN',\n",
    "    usecols=[\n",
    "        'ISIN',\n",
    "        'Company Name',\n",
    "        'Country Code',\n",
    "        'Region',\n",
    "        'GICS Sector',\n",
    "        'GICS Industry Group',\n",
    "        'GICS Industry',\n",
    "        'GICS Sub-Industry',\n",
    "        'MKTCAP_USD',\n",
    "        'PRICE_TO_SALES',\n",
    "        'SALES_USD'])\n",
    "results_df = pd.merge(\n",
    "    left=company_stats_df,\n",
    "    right=original_acwi_df,\n",
    "    left_index=True,\n",
    "    right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f95ac1-f57a-450d-9536-25646a8859ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37270a37-749a-44a7-ae97-3b4755c78bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.to_csv('msci_acwi_company_results.csv', index_label='ISIN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee562dc5-20a7-438e-af6e-90d3af0e50ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "old_results_df = pd.read_csv('/Users/emily/Downloads/msci_acwi_company_results.csv', index_col='ISIN')\n",
    "old_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e6d92a-1d80-4ea9-8244-71b4f9fc8c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    results_df['nature_access_flagged'].sort_index() != \n",
    "    old_results_df['nature_access_flags']).any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a055ca3-fe31-4336-845a-188759c0e8b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "(results_df['total_flagged'].sort_index() - old_results_df['total_flags']).sort_values()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
